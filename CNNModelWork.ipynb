{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNNModelWork",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AI4GoodProject/speechRecForMeeting/blob/master/CNNModelWork.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "J-aURtjMTCBm"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import cv2,glob\n",
        "import random\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "0.Data retrieving/some preprocessing\n"
      ],
      "metadata": {
        "id": "m-MYAjrZa8qd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "import pickle\n",
        "\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "DATA_PATH = \"/content/drive/My Drive/Team 6/processed-data\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11YR1UndQ77o",
        "outputId": "703234b9-9017-4619-c66a-0b0cc8a47e1d"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls \"/content/drive/My Drive/Team 6/processed-data\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F7H6MZXWRPNC",
        "outputId": "2076dff5-45f1-42cd-8480-66c5b4835b39"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dialogue-acts.pkl\t features.pkl\t     labels.pkl\n",
            "dialogue-acts-test.pkl\t features-test.pkl   labels-test.pkl\n",
            "dialogue-acts-whole.pkl  features-whole.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "features= open(DATA_PATH+'/features-test.pkl','rb')\n",
        "labels= open(DATA_PATH+'/labels-test.pkl','rb')\n",
        "features_list = pickle.load(features)\n",
        "#labels_list = pickle.load(labels)\n",
        "\n",
        "\n",
        "labels_list = [random.randint(0,1) for _ in range(len(features_list))]\n",
        "\n",
        "\n",
        "\n",
        "#print(\"features_list\",\"\\n\", features_list[:5])\n",
        "#print(\"length\", len(features_list)) \n",
        "#print(\"width\", len(features_list[0]))\n",
        "print(\"-----------------\")\n",
        "print(\"labels_list\",\"\\n\",labels_list[:5])\n",
        "print(\"length\", len(labels_list)) \n",
        "print(\"width\", labels_list[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cdoDKd7ORZdS",
        "outputId": "db80c4d9-2583-4ab7-e8a6-d337b13fb28a"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------\n",
            "labels_list \n",
            " [0, 0, 0, 1, 1]\n",
            "length 3790\n",
            "width 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def crossJoin (list1,list2):\n",
        "  crossJoined_list = []\n",
        "  \n",
        "  for i in range(0,len(list1)):\n",
        "    inner_list = []\n",
        "    for j in range(0,1):\n",
        "      inner_list.append(list1[i])\n",
        "      inner_list.append(list2[i])\n",
        "    crossJoined_list.append(inner_list)\n",
        "\n",
        "  return crossJoined_list"
      ],
      "metadata": {
        "id": "-x-SYM90-iwd"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for testing purpose\n",
        "\n",
        "list1 = np.array([['a', 'b'], ['c','d'],['e','f']])\n",
        "list2 = np.array([[True], [False], [True]])"
      ],
      "metadata": {
        "id": "C0vJ9Bli9tD6"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list3 = crossJoin (list1,list2)\n",
        "list3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C7fF1DN5AAyV",
        "outputId": "58f04a68-ffb2-4a21-d762-dfef71507aef"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[array(['a', 'b'], dtype='<U1'), array([ True])],\n",
              " [array(['c', 'd'], dtype='<U1'), array([False])],\n",
              " [array(['e', 'f'], dtype='<U1'), array([ True])]]"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for image in features_list:\n",
        "  print(image.shape)\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3yl8ME4BzeB_",
        "outputId": "0dac9941-3ab7-46b9-fed8-7cd42b12b4d2"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(128, 313)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(features_list[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Yp6n_YFQOeb",
        "outputId": "d5d329e1-fc1f-4c3c-8979-4c8bc7b2df1c"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[5.7969120e-04 2.8845244e-03 3.8505071e-03 ... 4.2184364e-02\n",
            "  9.9059632e-03 4.5957719e-03]\n",
            " [2.2720152e-03 2.8340286e-03 3.2133576e-03 ... 3.0660164e-01\n",
            "  9.4618261e-02 2.4500459e-02]\n",
            " [9.9112233e-04 4.0617207e-04 9.6240174e-04 ... 2.0881109e-01\n",
            "  5.9001476e-02 3.1543978e-02]\n",
            " ...\n",
            " [8.7587335e-07 5.3553856e-07 3.8149975e-07 ... 4.6525852e-04\n",
            "  2.4058839e-04 1.8763794e-04]\n",
            " [8.0240932e-07 4.7897174e-07 3.4212042e-07 ... 2.6049485e-04\n",
            "  1.2429411e-04 5.5625580e-05]\n",
            " [7.1721036e-07 5.9548421e-07 5.3247766e-07 ... 1.2215057e-04\n",
            "  5.6045861e-05 3.3594653e-05]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Train/validate/test split**"
      ],
      "metadata": {
        "id": "d-hzG5o3PGrg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.1 use np.stack to join the images into 3D tensor\n",
        "\n",
        "1.2 add one singleton axis (you can use np.expand_dims for that) to get 4D array with channels dimension equal to 1\n",
        "\n",
        "1.3 use train_test_split from sklearn because it allows to shuffle your data before splitting"
      ],
      "metadata": {
        "id": "Qwy0seHWE_mK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#1.1 convert a list of images(np.arrays) to a 3D tensor\n",
        "\n",
        "##?? can't directly change to tensor, cause got error of \"inconsistent shape\"\n",
        "\n",
        "#convert-a-list-of-numpy-array-to-torch-tensor-list\n",
        "tensor_list = [torch.from_numpy(item) for item in features_list]\n",
        "\n",
        "\n",
        "tensor_list = tensor_list[:100]\n",
        "labels_list = labels_list[:100]\n",
        "\n",
        "print(torch.stack(tensor_list).shape)\n",
        "print(torch.tensor(labels_list).shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i4f08wfME8Kk",
        "outputId": "25ac1669-b14a-4cda-8a68-b13cde033ca1"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([100, 128, 313])\n",
            "torch.Size([100])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#1.2 add one singleton axis (you can use np.expand_dims for that) to get 4D array with channels dimension equal to 1\n",
        "\n",
        "##?? since we are only look into 1 channel so no need to make it 4d?\n",
        "tensor = np.expand_dims(tensor_list,axis=1)\n",
        "\n",
        "#tensor.size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sutOOxtGOSec",
        "outputId": "dc4d8519-8cfd-4318-8dd1-c95bcf39b95f"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/shape_base.py:591: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  a = asanyarray(a)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/shape_base.py:591: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  a = asanyarray(a)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#1.3 use train_test_split from sklearn because it allows to shuffle your data before splitting\n",
        "X_train,X_test,Y_train,Y_test = train_test_split(tensor_list, labels_list, test_size=0.1, train_size=0.8, random_state=1, shuffle=True)\n",
        "\n",
        "X_val, X_test, Y_val, Y_test = train_test_split(X_test, Y_test, test_size=0.5, random_state=1)\n",
        "#print(len(X_test),len(X_train))\n",
        "#print(len(Y_test),len(Y_train))\n",
        "#print(len(X_val),len(Y_val))"
      ],
      "metadata": {
        "id": "Eoo3JxJwE3bW"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = crossJoin(X_train, Y_train)\n",
        "val_data = crossJoin(X_val, Y_val)\n",
        "test_data = crossJoin(X_test,Y_test)"
      ],
      "metadata": {
        "id": "RB2vF9lCAlp0"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train_data))\n",
        "print(train_data[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZF7gZ7iUm7jn",
        "outputId": "5a900a7c-b3aa-4a84-80d6-62d7fcc5329c"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "80\n",
            "[tensor([[9.6868e-03, 3.2697e-02, 3.0283e-02,  ..., 7.9474e-02, 1.7097e-01,\n",
            "         1.4461e-01],\n",
            "        [6.3806e-03, 1.1808e-02, 2.1545e-02,  ..., 2.6344e-01, 8.2620e-01,\n",
            "         5.5500e-01],\n",
            "        [2.6212e-03, 1.0034e-02, 1.7256e-02,  ..., 2.4510e-01, 3.4536e-01,\n",
            "         7.3136e-01],\n",
            "        ...,\n",
            "        [3.0039e-07, 5.5057e-07, 1.6090e-05,  ..., 2.5093e-04, 3.3191e-03,\n",
            "         8.8956e-03],\n",
            "        [2.4430e-07, 5.4194e-07, 8.8940e-06,  ..., 4.4598e-04, 3.5708e-03,\n",
            "         9.0889e-03],\n",
            "        [2.0626e-07, 7.0101e-07, 1.7646e-05,  ..., 4.9756e-04, 2.7163e-03,\n",
            "         6.9803e-03]]), 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#RuntimeError: Given groups=1, weight of size [6, 4, 5, 5], expected input[1, 2, 128, 313] to have 4 channels, but got 2 channels instead\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(4, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 4, 5)\n",
        "        self.fc1 = nn.Linear(2175,120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "CNN = CNN()"
      ],
      "metadata": {
        "id": "yInB4eeN7Vfw"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#evaluation\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(CNN.parameters(), lr=0.01, momentum=0.9)"
      ],
      "metadata": {
        "id": "ihB0M6aLA3Xe"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_dataloader = DataLoader(train_data, batch_size=4, shuffle=True)\n",
        "\n",
        "test_dataloader = DataLoader(test_data, batch_size=4, shuffle=True)"
      ],
      "metadata": {
        "id": "STETCGada4LK"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(2):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(train_dataloader, 0):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = CNN(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 4 == 3:    # print every 4 mini-batches\n",
        "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 4:.3f}')\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6HfCK677foE-",
        "outputId": "6b1144c5-de56-470d-c154-015b8a34c2a7"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1,     4] loss: 2.255\n",
            "[1,     8] loss: 2.204\n",
            "[1,    12] loss: 2.254\n",
            "[1,    16] loss: 2.221\n",
            "[1,    20] loss: 2.250\n",
            "[2,     4] loss: 2.248\n",
            "[2,     8] loss: 2.267\n",
            "[2,    12] loss: 2.241\n",
            "[2,    16] loss: 2.210\n",
            "[2,    20] loss: 2.259\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "use_gpu = torch.cuda.is_available()"
      ],
      "metadata": {
        "id": "H1iur-GOXIoR"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "9ArK1te0aXRz"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prediction(loader, model):\n",
        "\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  losses = 0\n",
        "\n",
        "  for i, (images, labels) in enumerate(loader):\n",
        "    if use_gpu:\n",
        "      # switch tensor type to GPU\n",
        "      images = images.cuda()\n",
        "      labels = labels.cuda()\n",
        "    \n",
        "    outputs = model(images)\n",
        "    \n",
        "    loss = criterion(outputs, labels)\n",
        "  \n",
        "    _, predictions = torch.max(outputs, 1)\n",
        "  \n",
        "    correct += torch.sum(labels == predictions).item()\n",
        "    total += labels.shape[0]\n",
        "    \n",
        "    losses += loss.data.item()\n",
        "    \n",
        "  return losses/len(list(loader)), 1 - correct/total # we need to normalize loss with respect to the number of batches "
      ],
      "metadata": {
        "id": "KGoQlJfLXDuN"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_losses = []\n",
        "test_losses = []\n",
        "\n",
        "train_error_rates = []\n",
        "test_error_rates = []\n",
        "\n",
        "\n",
        "if use_gpu:\n",
        "  # switch model to GPU\n",
        "  CNN.cuda()\n",
        "\n",
        "num_epochs = 5\n",
        "\n",
        "for epoch in range(num_epochs): \n",
        "  train_loss = 0 \n",
        "  n_iter = 0 \n",
        "  total = 0\n",
        "  correct = 0\n",
        "\n",
        "  for i, (images, labels) in enumerate(train_dataloader): \n",
        "    optimizer.zero_grad() \n",
        "\n",
        "    if use_gpu: \n",
        "      images = images.cuda()\n",
        "      labels = labels.cuda()\n",
        "\n",
        "    outputs = CNN(images)\n",
        "    \n",
        "    # to compute the train_error_rates  \n",
        "    _, predictions = torch.max(outputs, 1)\n",
        "    correct += torch.sum(labels == predictions).item()\n",
        "    total += labels.shape[0]\n",
        "    \n",
        "    # compute loss \n",
        "    loss_bs = criterion(outputs, labels)\n",
        "    # compute gradients\n",
        "    loss_bs.backward()\n",
        "    # update weights\n",
        "    optimizer.step()\n",
        "\n",
        "    train_loss += loss_bs.detach().item()\n",
        "\n",
        "    n_iter += 1\n",
        "\n",
        "  train_error_rate = 1 - correct/total\n",
        "\n",
        "  with torch.no_grad():\n",
        "    test_loss, test_error_rate = prediction(test_dataloader, CNN)\n",
        "\n",
        "  train_error_rates.append(train_error_rate)\n",
        "  test_error_rates.append(test_error_rate)\n",
        "  train_losses.append(train_loss/n_iter)\n",
        "  test_losses.append(test_loss)\n",
        "\n",
        "  if epoch%1 == 0:\n",
        "    print('Epoch: {}/{}, Loss: {:.4f}, Error Rate: {:.1f}%'.format(epoch+1, num_epochs, train_loss/n_iter, 100*train_error_rate))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        },
        "id": "yPHz_tKTW5IU",
        "outputId": "b21a1a66-8a8f-4616-d657-cfeee1e4602c"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-75-c0c695933f62>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m     \u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_error_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCNN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0mtrain_error_rates\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_error_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-59-674e4b6b73d1>\u001b[0m in \u001b[0;36mprediction\u001b[0;34m(loader, model)\u001b[0m\n\u001b[1;32m     11\u001b[0m       \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-69-97c55d729b1a>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# flatten all dimensions except batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 447\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    448\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    442\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    443\u001b[0m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0;32m--> 444\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [6, 4, 5, 5], expected input[1, 1, 128, 313] to have 4 channels, but got 1 channels instead"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 8))\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(train_losses, label='train', marker='o', alpha=0.7)\n",
        "plt.plot(test_losses, label='test', marker='o', alpha=0.7)\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.title('Loss')\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(train_error_rates, label='train', marker='o', alpha=0.7)\n",
        "plt.plot(test_error_rates, label='test', marker='o', alpha=0.7)\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.title('Error rate')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GNVMO4p_X6Ir"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "should follow this format\n",
        "https://colab.research.google.com/drive/1HtJpNyh6oWabiVcDUG_2TJ34TtVo5JH8?authuser=2#scrollTo=D2lKHjcfscif"
      ],
      "metadata": {
        "id": "ZtHNRhD2ejIj"
      }
    }
  ]
}